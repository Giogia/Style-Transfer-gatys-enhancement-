{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Style_transfer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Giogia/gatys_piu_bello/blob/master/Style_Transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "xVS3ikr1mehX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "IMPORT"
      ]
    },
    {
      "metadata": {
        "id": "_gWU4wyx_6n_",
        "colab_type": "code",
        "outputId": "a5c22180-6345-49db-ef8d-885a005f5958",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install moviepy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.6/dist-packages (0.2.3.5)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (4.3.0)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (2.4.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from moviepy) (1.14.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->imageio<3.0,>=2.1.2->moviepy) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BmebnUUOBGRK",
        "colab_type": "code",
        "outputId": "1d20a74e-68d4-404d-c7aa-d060693c24d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "!imageio_download_bin ffmpeg"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ascertaining binaries for: ffmpeg.\n",
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Error while fetching file: ('The read operation timed out',).\n",
            "Error while fetching file: ('The read operation timed out',).\n",
            "Try 3. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1687552/45929032 bytes (3.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5414912/45929032 bytes (11.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b9175040/45929032 bytes (20.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b12959744/45929032 bytes (28.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16719872/45929032 bytes (36.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b20520960/45929032 bytes (44.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b24248320/45929032 bytes (52.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b28065792/45929032 bytes (61.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b31727616/45929032 bytes (69.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b35454976/45929032 bytes (77.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b39288832/45929032 bytes (85.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b43081728/45929032 bytes (93.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "URLc5gsjl_Jt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.eager as tfe\n",
        "import tensorflow.keras as models\n",
        "\n",
        "from google.colab import files\n",
        "from tensorflow import clip_by_value\n",
        "from tensorflow import enable_eager_execution\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from numpy import clip, expand_dims, squeeze, array, random\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from pathlib import Path\n",
        "\n",
        "import moviepy.video.io.ffmpeg_writer as ffmpeg_writer\n",
        "import numpy as np\n",
        "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
        "from IPython.display import HTML, display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BWb96dmdgows",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "CNN"
      ]
    },
    {
      "metadata": {
        "id": "sVwQ_6NhgSRd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class VGG19_c:\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        # here you say where you want to take the features for the content\n",
        "        self.contentLayers = ['block4_conv2']\n",
        "\n",
        "        # here you say where you want to take the features for the style\n",
        "        self.styleLayers = ['block1_conv1',\n",
        "                              'block2_conv1',\n",
        "                              'block3_conv1',\n",
        "                              'block4_conv1',\n",
        "                              'block5_conv1']\n",
        "        self.content_layers_num = len(self.contentLayers)\n",
        "        self.style_layers_num = len(self.styleLayers)\n",
        "\n",
        "\n",
        "        self.model = self.getModel()\n",
        "\n",
        "        # after setting model not trainable we also set the layers not trainable\n",
        "        for layer in self.model.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "\n",
        "    def get_content_features(self,img):\n",
        "        return self.get_output_features(img)[0]\n",
        "\n",
        "\n",
        "    def get_style_features(self, img):\n",
        "        return self.get_output_features(img)[1]\n",
        "\n",
        "\n",
        "    def get_output_features(self, content):\n",
        "\n",
        "        features = self.model(content)\n",
        "\n",
        "        # for the content take only the content layers from 0 to len of content\n",
        "        content = [style_content[0] for style_content in features[self.style_layers_num:]]\n",
        "\n",
        "        # for style take only the style layers from len of content to len of content + len of style\n",
        "        style = [style[0] for style in features[:self.style_layers_num]]\n",
        "\n",
        "        return content, style\n",
        "\n",
        "\n",
        "    def getModel(self):\n",
        "\n",
        "        # we load the VGG19 pretrained with the dataset imagenet and we don't include the 3 fully connected layers on\n",
        "        # top of theVGG19\n",
        "        vgg = VGG19(include_top=False, weights='imagenet')\n",
        "\n",
        "        # we freeze the weights and the variables\n",
        "        vgg.trainable = False\n",
        "\n",
        "        style_feature = []\n",
        "        for i in self.styleLayers:\n",
        "            style_feature.append(vgg.get_layer(i).output)\n",
        "\n",
        "        content_feature = []\n",
        "        for i in self.contentLayers:\n",
        "            content_feature.append(vgg.get_layer(i).output)\n",
        "\n",
        "        #using the Keras API we return the model of the CNN\n",
        "        return models.Model(vgg.input, style_feature + content_feature)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bYTUfT2JgtV_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "IMAGE"
      ]
    },
    {
      "metadata": {
        "id": "p32FYPgpgdoO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_image(path):\n",
        "\n",
        "    max_dim = 1024\n",
        "\n",
        "    img = Image.open(path)\n",
        "\n",
        "    # resize image to max_dim\n",
        "    scale = max_dim / max(img.size)\n",
        "\n",
        "    if scale < 1:\n",
        "        scaled_width = round(img.size[0] * scale)\n",
        "        scaled_height = round(img.size[1] * scale)\n",
        "        img = img.resize((scaled_width, scaled_height))\n",
        "\n",
        "    #convert greyscale to rgb\n",
        "    img = img.convert(\"RGB\")\n",
        "\n",
        "    img = img_to_array(img)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def save_image(path, img):\n",
        "\n",
        "    img = Image.fromarray(clip(img, 0, 255).astype('uint8'))\n",
        "    img.save(path, 'JPEG')\n",
        "\n",
        "\n",
        "def preprocess_image(img):\n",
        "\n",
        "    img = expand_dims(img, axis=0)\n",
        "\n",
        "    #normalize by mean = [103.939, 116.779, 123.68] and with channels BGR\n",
        "    img = preprocess_input(img)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def postprocess_image(processed_img):\n",
        "\n",
        "    img = processed_img.copy()\n",
        "\n",
        "    # shape (1, h, w, d) to (h, w, d)\n",
        "    if len(img.shape) == 4:\n",
        "        img = squeeze(img, axis=0)\n",
        "    if len(img.shape) != 3:\n",
        "        raise ValueError(\"Invalid input to deprocessing image\")\n",
        "\n",
        "    # Remove VGG mean\n",
        "    img[:, :, 0] += 103.939\n",
        "    img[:, :, 1] += 116.779\n",
        "    img[:, :, 2] += 123.68\n",
        "\n",
        "    # rgb to bgr\n",
        "    img = img[:, :, ::-1]\n",
        "\n",
        "    #cast to values within (-255,255)\n",
        "    img = clip(img, 0, 255).astype('uint8')\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def clip_image(img):\n",
        "\n",
        "    norm_means = array([103.939, 116.779, 123.68])\n",
        "    min_vals = -norm_means\n",
        "    max_vals = 255 - norm_means\n",
        "\n",
        "    img = clip_by_value(img, min_vals, max_vals)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def show_image(img, title=None):\n",
        "\n",
        "    # Normalize for display\n",
        "    out = img.astype('uint8')\n",
        "\n",
        "    # Remove the batch dimension\n",
        "    if len(img.shape) == 4:\n",
        "        out = squeeze(out, axis=0)\n",
        "\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "\n",
        "    plt.imshow(out)\n",
        "\n",
        "\n",
        "def generate_noise_image(img):\n",
        "\n",
        "    img = random.uniform(-20,20,img.shape).astype('uint8')\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def show_content_style(content_path, style_path):\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "\n",
        "    content = load_image(content_path)\n",
        "    style = load_image(style_path)\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    show_image(content, 'Content')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    show_image(style, 'Style')\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cSkZidwqg4Uy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "LOSS"
      ]
    },
    {
      "metadata": {
        "id": "jKEPV9Mfg07z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def g_matrix(tensor):\n",
        "\n",
        "    channels = int(tensor.shape[-1])\n",
        "\n",
        "    # reshape as 1-Dim array dividing it per channel\n",
        "    a = tf.reshape(tensor, [-1, channels])\n",
        "\n",
        "    # compute the matrix a*a^t and then divide by the dimension\n",
        "    return tf.matmul(a, a, transpose_a=True) / tf.cast(tf.shape(a)[0], tf.float32)\n",
        "\n",
        "\n",
        "def get_content_loss(content, target):\n",
        "\n",
        "    return tf.reduce_mean(tf.square(content - target))\n",
        "\n",
        "\n",
        "def get_style_loss(style, g_target):\n",
        "\n",
        "    g_style = g_matrix(style)\n",
        "    height, width, channels = style.get_shape().as_list()\n",
        "    weight = channels ** 2\n",
        "\n",
        "\n",
        "    return tf.reduce_mean(tf.square(g_style - g_target))/weight\n",
        "\n",
        "\n",
        "def accumulate_loss(img_feature, layers_n, noise_feature, loss):\n",
        "\n",
        "    score = 0\n",
        "    weight_per_layer = 1.0 / float(layers_n)\n",
        "\n",
        "    for target, comb_content in zip(img_feature, noise_feature):\n",
        "        score += weight_per_layer * loss(comb_content, target)\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "def compute_loss(noise_features, img_features, loss_w, layers_n):\n",
        "    \"\"\"This function will compute the loss total loss.\n",
        "\n",
        "    Arguments:\n",
        "      noise_features: The content and style of the white noise\n",
        "      loss_w: The weights of each contribution of each loss function.\n",
        "        (style weight, content weight, and total variation weight)\n",
        "      img_features: Content and style features\n",
        "      loss_w: Weights of the elements\n",
        "      layers_n: Number of content and style layers\n",
        "\n",
        "    Returns:\n",
        "      returns the total loss\n",
        "    \"\"\"\n",
        "\n",
        "    # Accumulate content losses from all layers\n",
        "    content_score = accumulate_loss(img_features[0], layers_n[0], noise_features[0], get_content_loss)\n",
        "\n",
        "    # Accumulate style losses from all layers\n",
        "    style_score = accumulate_loss(img_features[1], layers_n[1], noise_features[1], get_style_loss)\n",
        "\n",
        "    # Here, we equally weight each contribution of each loss layer\n",
        "    content_score *= loss_w[0]\n",
        "    style_score *= loss_w[1]\n",
        "\n",
        "    return style_score + content_score\n",
        "\n",
        "\n",
        "def compute_gradient(noise_img, noise_features_gen, img_features, loss_w, layers_n):\n",
        "\n",
        "    with tf.GradientTape() as g:\n",
        "        loss = compute_loss(noise_features_gen(noise_img), img_features, loss_w, layers_n)\n",
        "\n",
        "    # Compute gradients wrt input image\n",
        "    return g.gradient(loss, noise_img), loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "80qyy1Aw62ys",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "IMAGE STYLE TRANSFER"
      ]
    },
    {
      "metadata": {
        "id": "IQwxfvI-gLkj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def image_style_transfer(content_path, style_path, output_path, iterations=1000, content_weight=1e0, style_weight=1e2, learning_rate=5):\n",
        "\n",
        "    #create images\n",
        "    content = load_image(content_path)\n",
        "    style = load_image(style_path)\n",
        "    noise = generate_noise_image(content)\n",
        "\n",
        "    content = preprocess_image(content)\n",
        "    style = preprocess_image(style)\n",
        "    noise = preprocess_image(noise)\n",
        "    percentage = 0\n",
        "    noise = percentage * noise + (1 - percentage) * content\n",
        "\n",
        "    noise = tfe.Variable(noise, dtype=tf.float32)\n",
        "\n",
        "    # create model\n",
        "    vgg = VGG19_c()\n",
        "    loss_weights = content_weight, style_weight\n",
        "    layers_number = vgg.content_layers_num , vgg.style_layers_num\n",
        "\n",
        "    #create features\n",
        "    content_features = vgg.get_content_features(content)\n",
        "    style_features = vgg.get_style_features(style)\n",
        "    gram_matrix_features = [g_matrix(feature) for feature in style_features]\n",
        "\n",
        "    img_features = content_features, gram_matrix_features\n",
        "\n",
        "    #create optimizer\n",
        "    opt = tf.train.AdamOptimizer(learning_rate, beta1=0.99, epsilon=1e-1)\n",
        "\n",
        "    #store best results\n",
        "    best_loss, best_img = float('inf'), None\n",
        "\n",
        "    #plt.ion()\n",
        "    for i in range(iterations):\n",
        "\n",
        "        grads, loss = compute_gradient(noise,vgg.get_output_features,img_features,loss_weights,layers_number)\n",
        "\n",
        "        opt.apply_gradients([(grads, noise)])\n",
        "\n",
        "        clipped = clip_image(noise)\n",
        "        noise.assign(clipped)\n",
        "\n",
        "\n",
        "        if loss < best_loss:\n",
        "\n",
        "            # Update best loss and best image from total loss.\n",
        "            best_loss = loss\n",
        "            best_img = postprocess_image(noise.numpy())\n",
        "\n",
        "        if i %100 == 0:\n",
        "            print(\"Iterations:\" + str(i))\n",
        "            plot_img = noise.numpy()\n",
        "            plot_img = postprocess_image(plot_img)\n",
        "            show_image(plot_img)\n",
        "            plt.show()\n",
        "            print(\"Current Loss:\" +str(loss.numpy())+\"  Best Loss:\"+str(best_loss.numpy()))\n",
        "            progressbar = display(progress(0,99), display_id=True)\n",
        "            \n",
        "        progressbar.update(progress(i%100, 99))\n",
        "\n",
        "    save_image(output_path,best_img)\n",
        "\n",
        "    return best_loss, best_img\n",
        "  \n",
        " \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-fO62Mx0NYhS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "PROGRESS BAR"
      ]
    },
    {
      "metadata": {
        "id": "Ts_63i2dJBa9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def progress(value, max=100):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(value=value, max=max))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nQztxZEO2AtJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TRANSFORM"
      ]
    },
    {
      "metadata": {
        "id": "5zDVCxH41vem",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "WEIGHTS_INIT_STDEV = .1\n",
        "\n",
        "\n",
        "def net(image):\n",
        "\n",
        "    conv1 = conv_layer(image, 32, 9, 1)\n",
        "    conv2 = conv_layer(conv1, 64, 3, 2)\n",
        "    conv3 = conv_layer(conv2, 128, 3, 2)\n",
        "    resid1 = residual_block(conv3, 3)\n",
        "    resid2 = residual_block(resid1, 3)\n",
        "    resid3 = residual_block(resid2, 3)\n",
        "    resid4 = residual_block(resid3, 3)\n",
        "    resid5 = residual_block(resid4, 3)\n",
        "    conv_t1 = conv_tranpose_layer(resid5, 64, 3, 2)\n",
        "    conv_t2 = conv_tranpose_layer(conv_t1, 32, 3, 2)\n",
        "    conv_t3 = conv_layer(conv_t2, 3, 9, 1, is_relu=False)\n",
        "    preds = tf.nn.tanh(conv_t3) * 150 + 255./2\n",
        "\n",
        "    return preds\n",
        "\n",
        "\n",
        "def conv_layer(image, filter_number, filter_size, strides, is_relu=True):\n",
        "\n",
        "    # make the convolution of the image and return the convolution\n",
        "\n",
        "    weights_initialization = conv_initialization_vars(image, filter_number, filter_size)\n",
        "    strides_shape = [1, strides, strides, 1]\n",
        "\n",
        "    # apply the filter to the image with a 2d convolution\n",
        "    image = tf.nn.conv2d(image, weights_initialization, strides_shape, padding='SAME')\n",
        "\n",
        "    image = _instance_norm(image)\n",
        "\n",
        "    if is_relu:\n",
        "\n",
        "        image = tf.nn.relu(image)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def conv_tranpose_layer(img, filter_number, filter_size, strides):\n",
        "\n",
        "    weights_initialized = conv_initialization_vars(img, filter_number, filter_size, transpose=True)\n",
        "\n",
        "    batch_size, rows, cols, in_channels = [i for i in img.get_shape()]\n",
        "    new_rows, new_cols = int(rows * strides), int(cols * strides)\n",
        "    new_shape = [batch_size, new_rows, new_cols, filter_number]\n",
        "\n",
        "    tf_shape = tf.stack(new_shape)\n",
        "    strides_shape = [1, strides, strides, 1]\n",
        "\n",
        "    convolution = tf.nn.conv2d_transpose(img, weights_initialized, tf_shape, strides_shape, padding='SAME')\n",
        "    convolution = _instance_norm(convolution)\n",
        "\n",
        "    return tf.nn.relu(convolution)\n",
        "\n",
        "\n",
        "def residual_block(img, filter_size=3):\n",
        "\n",
        "    tmp_convolution = conv_layer(img, 128, filter_size, 1)\n",
        "\n",
        "    # add the convolution to the original image\n",
        "    return img + conv_layer(tmp_convolution, 128, filter_size, 1, is_relu=False)\n",
        "\n",
        "\n",
        "def _instance_norm(img, train=True):\n",
        "\n",
        "    # set the shape of the input img\n",
        "    batch_size, rows, cols, in_channels = [i for i in img.get_shape()]\n",
        "\n",
        "    var_shape = [in_channels]\n",
        "\n",
        "    # calculate the mean and the variance of the img\n",
        "    mu, sigma_sq = tf.nn.moments(img, [1, 2], keep_dims=True)\n",
        "\n",
        "    shift = tf.Variable(tf.zeros(var_shape))\n",
        "    scale = tf.Variable(tf.ones(var_shape))\n",
        "\n",
        "    epsilon = 1e-3\n",
        "\n",
        "    # normalize the img input wrt the mean and the variance calculated\n",
        "    normalized = (img - mu) / (sigma_sq + epsilon) ** (.5)\n",
        "\n",
        "    return scale * normalized + shift\n",
        "\n",
        "\n",
        "def conv_initialization_vars(net, out_channels, filter_size, transpose=False):\n",
        "\n",
        "    _, rows, cols, in_channels = [i.value for i in net.get_shape()]\n",
        "\n",
        "    if not transpose:\n",
        "\n",
        "        weights_shape = [filter_size, filter_size, in_channels, out_channels]\n",
        "\n",
        "    else:\n",
        "\n",
        "        weights_shape = [filter_size, filter_size, out_channels, in_channels]\n",
        "\n",
        "    # with tf truncated we output rnd values rom a truncated normal distribution\n",
        "    weights_init = tf.Variable(tf.truncated_normal(weights_shape, stddev=WEIGHTS_INIT_STDEV, seed=1), dtype=tf.float32)\n",
        "\n",
        "    return weights_init"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BKscEyJX2D4_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "VIDEO STYLE TRANSFER"
      ]
    },
    {
      "metadata": {
        "id": "woxCbccY2MD_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DEVICE = '/gpu:0'\n",
        "EX = Exception(\"Please provide a model\")\n",
        "\n",
        "\n",
        "def video_style_transfer(input_path, model_path, output_path, batch_s=4):\n",
        "\n",
        "    video = VideoFileClip(input_path, audio=False)\n",
        "    video_w = ffmpeg_writer.FFMPEG_VideoWriter(output_path, video.size, video.fps, codec=\"libx264\",\n",
        "                                               preset=\"medium\", bitrate=\"2000k\",\n",
        "                                               audiofile=input_path, threads=None,\n",
        "                                               ffmpeg_params=None)\n",
        "\n",
        "    with tf.Graph().as_default(), tf.Session() as session:\n",
        "        \n",
        "        print(\"Loading model, it may take some time\")\n",
        "        video_iter = list(video.iter_frames())\n",
        "        batch_l = [video_iter[i:i + batch_s] for i in range(0, len(video_iter), batch_s)]\n",
        "        while len(batch_l[-1]) < batch_s:\n",
        "            batch_l[-1].append(batch_l[-1][-1])\n",
        "\n",
        "        video_wip = np.array(batch_l, dtype=np.float32)\n",
        "        place_holder = tf.placeholder(tf.float32, shape=video_wip.shape[1:], name='place_holder')\n",
        "        wip = net(place_holder)\n",
        "\n",
        "        p_loader = tf.train.Saver()\n",
        "                \n",
        "        if os.path.isdir(model_path):\n",
        "\n",
        "            model = tf.train.get_checkpoint_state(model_path)\n",
        "            is_valid = model.model_checkpoint_path\n",
        "\n",
        "            if model is not None and is_valid:\n",
        "                p_loader.restore(session, is_valid)\n",
        "            else:\n",
        "                raise EX\n",
        "        else:\n",
        "            p_loader.restore(session, model_path)\n",
        "\n",
        "        # The information about size in the video files are: 'width, height'\n",
        "        # In *** the dimensions are 'height, width'\n",
        "        #shape = (batch_s, video.size[1], video.size[0], 3)\n",
        "        # TODO check if it's ok without shape\n",
        "        progressbar = display(progress(0,len(video_wip)-1), display_id=True)\n",
        "        for i in range(len(video_wip)):\n",
        "          \n",
        "            progressbar.update(progress(i,len(video_wip)-1))\n",
        "            r_res = session.run(wip, feed_dict={place_holder: video_wip[i]})\n",
        "            for r in r_res:\n",
        "                video_w.write_frame(np.clip(r, 0, 255).astype(np.uint8))\n",
        "            #print(\"processed \" + str(i+1) + \" out of \" + str(len(video_wip)) + \" batches\", end = '\\r')\n",
        "\n",
        "        video_w.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SGJ6Tk7HU03U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "GATYS VIDEO"
      ]
    },
    {
      "metadata": {
        "id": "hMQtEY0mUx9S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_style_transfer(content, style, iterations=100, content_weight=1e0, style_weight=1e2, learning_rate=5):\n",
        "\n",
        "    vgg = VGG19_c()\n",
        "\n",
        "    noise = [preprocess_image(generate_noise_image(c)) for c in content]\n",
        "    content = [preprocess_image(c) for c in content]\n",
        "    style = preprocess_image(style)\n",
        "\n",
        "    p = 0\n",
        "\n",
        "    noise = [p * n + (1 - p) * c for n, c in zip(noise, content)]\n",
        "\n",
        "    noise = [tfe.Variable(n, dtype=tf.float32) for n in noise]\n",
        "\n",
        "    # create model\n",
        "    loss_weights = content_weight, style_weight\n",
        "    layers_number = vgg.content_layers_num, vgg.style_layers_num\n",
        "\n",
        "    style_features = vgg.get_style_features(style)\n",
        "    opt = tf.train.AdamOptimizer(learning_rate, beta1=0.99, epsilon=1e-1)\n",
        "    # precompute features\n",
        "    print(\"computing features, please wait\")\n",
        "    content_features = [vgg.get_content_features(c) for c in content]\n",
        "    gram_matrix_features = [g_matrix(feature) for feature in style_features]\n",
        "    # create features\n",
        "    img_features = [(cf, gram_matrix_features) for cf in content_features]\n",
        "    best = [(float('inf'), None) for n in noise]\n",
        "    # overall loss\n",
        "\n",
        "    for i in range(iterations):\n",
        "        print(\"computing iteration \" + str(i+1))\n",
        "        for index in range(len(content)):\n",
        "            grads, loss = compute_gradient(noise[index], vgg.get_output_features, img_features[index], loss_weights, layers_number)\n",
        "            opt.apply_gradients([(grads, noise[index])])\n",
        "            if loss < best[index][0]:\n",
        "                # Update best loss and best image from total loss.\n",
        "                best[index] = loss, postprocess_image(noise[index].numpy())\n",
        "            noise[index].assign(clip_image(noise[index]))\n",
        "    return [b[1] for b in best]\n",
        "\n",
        "\n",
        "def video_style_transfer_gatys(video_path, style_path, output_path, batch_s=15):\n",
        "\n",
        "    video = VideoFileClip(video_path, audio=False)\n",
        "    video_w = ffmpeg_writer.FFMPEG_VideoWriter(output_path, video.size, video.fps, codec=\"libx264\",\n",
        "                                               preset=\"medium\", bitrate=\"2000k\",\n",
        "                                               audiofile=video_path, threads=None,\n",
        "                                               ffmpeg_params=None)\n",
        "\n",
        "    style = load_image(style_path)\n",
        "    content = [c for c in video.iter_frames()]\n",
        "    batch_l = [content[i:i + batch_s] for i in range(0, len(content), batch_s)]\n",
        "    for b in batch_l:\n",
        "        frames = run_style_transfer(b, style)\n",
        "        for f in frames:\n",
        "            video_w.write_frame(f)\n",
        "    video_w.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K2vd75pWgxOB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "STYLE TRANSFER"
      ]
    },
    {
      "metadata": {
        "id": "bRiZZYOFiJmM",
        "colab_type": "code",
        "outputId": "78871f22-c4e1-4afa-819b-e0a240aab8d4",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 11433
        }
      },
      "cell_type": "code",
      "source": [
        "PATH = os.getcwd()\n",
        "IMAGES_PATH = PATH + '/Images'\n",
        "VIDEOS_PATH = PATH + '/Videos'\n",
        "MODELS_PATH = PATH + '/Models'\n",
        "\n",
        "\n",
        "def find_file(filename, directory):\n",
        "    for file in os.listdir(directory):\n",
        "        if os.path.splitext(file)[0] == filename:\n",
        "            return file\n",
        "\n",
        "    return None\n",
        "\n",
        "    \n",
        "def create_directory(path):\n",
        "    \n",
        "    if not(os.path.isdir(path)):\n",
        "            os.mkdir(path)\n",
        "  \n",
        "  \n",
        "def upload_files(path,number, message):\n",
        "    \n",
        "    while(len(os.listdir(path))<number):\n",
        "            print(\"Please upload at least \"+message)\n",
        "            os.chdir(path)\n",
        "            files.upload()\n",
        "            os.chdir(PATH)\n",
        "            time.sleep(30)\n",
        "    \n",
        "      \n",
        "def list_files(path):\n",
        "  \n",
        "    for file in os.listdir(Path(path)):\n",
        "            print(os.path.splitext(file)[0])\n",
        "        \n",
        "\n",
        "def check_error(var,path):\n",
        "  \n",
        "    while(var==None):\n",
        "            print(\"Please insert a correct Name (case sensitive input)\")\n",
        "            list_files(path)\n",
        "            var = find_file(input(),Path(path))\n",
        "            \n",
        "    return var\n",
        "        \n",
        "        \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    tf.enable_eager_execution()\n",
        "    #print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
        "        \n",
        "    choice = input(\"Select one of the following options:\\n\"\n",
        "                    \"1 - Style Transfer for Images\\n\"\n",
        "                    \"2 - Style Transfer for Videos\\n\"\n",
        "                    \"3 - Style Transfer for Videos with Gatys\\n\")\n",
        "\n",
        "    \n",
        "    if choice == '1':\n",
        "\n",
        "        create_directory(IMAGES_PATH)\n",
        "        upload_files(IMAGES_PATH,2,\"two images\")\n",
        "\n",
        "        print(\"Select Content Image:\")\n",
        "\n",
        "        list_files(IMAGES_PATH)\n",
        "\n",
        "        content = find_file(input(),Path(IMAGES_PATH))\n",
        "        content = check_error(content,IMAGES_PATH)\n",
        "        content_path  = Path(IMAGES_PATH + \"/\" + content)\n",
        "\n",
        "        print(\"Select Style Image:\")\n",
        "        \n",
        "        list_files(IMAGES_PATH)\n",
        "        \n",
        "        style = find_file(input(),Path(IMAGES_PATH))\n",
        "        style = check_error(style,IMAGES_PATH)\n",
        "        style_path = Path(IMAGES_PATH + \"/\" + style)\n",
        "        \n",
        "        output =  'Result' + '_' + os.path.splitext(content)[0] + '_' + os.path.splitext(style)[0]\n",
        "        output_path = Path(PATH +\"/\"+ output + \".jpg\")\n",
        "\n",
        "        show_content_style(content_path, style_path)\n",
        "\n",
        "        best_loss,best_img = image_style_transfer(content_path, style_path, output_path, iterations=3000)\n",
        "\n",
        "        print(\"Final Loss: \" + str(best_loss.numpy()))\n",
        "        show_image(best_img, output)\n",
        "        plt.show()\n",
        "\n",
        "        print(\"image saved in Files folder, refresh Files to see it\")\n",
        "        \n",
        "        files.download(output_path)\n",
        "        \n",
        "\n",
        "    if choice == '2':\n",
        "      \n",
        "        create_directory(VIDEOS_PATH)\n",
        "        upload_files(VIDEOS_PATH,1,\"one video\")\n",
        "   \n",
        "        print(\"Select Content Video:\")\n",
        "\n",
        "        list_files(VIDEOS_PATH)\n",
        "        \n",
        "        content = find_file(input(),Path(VIDEOS_PATH))\n",
        "        content = check_error(content,VIDEOS_PATH)\n",
        "        content_path  = Path(VIDEOS_PATH + \"/\" + content)\n",
        "\n",
        "        create_directory(MODELS_PATH)\n",
        "        upload_files(MODELS_PATH,1,\"one model\")\n",
        "\n",
        "        print(\"Select Style Model:\")\n",
        "\n",
        "        list_files(MODELS_PATH)\n",
        "\n",
        "        model = find_file(input(),Path(MODELS_PATH))\n",
        "        model = check_error(model,MODELS_PATH)\n",
        "        model_path = Path(MODELS_PATH + \"/\" + model)\n",
        "        \n",
        "        output =  'Result' + '_' + os.path.splitext(content)[0] + '_' + os.path.splitext(model)[0]\n",
        "        output_path = Path(PATH + \"/\" + output + \".mp4\")\n",
        "\n",
        "        video_style_transfer(str(content_path), str(model_path), str(output_path), batch_s=4)\n",
        "\n",
        "        print(\"video saved in Files folder, refresh Files to see it\")\n",
        "        \n",
        "        if(os.path.splitext(content)[1]==\".mp4\"):\n",
        "            files.download(output_path)\n",
        "            \n",
        "    if choice == '3':\n",
        "      \n",
        "        create_directory(VIDEOS_PATH)\n",
        "        upload_files(VIDEOS_PATH,1,\"one video\")\n",
        "   \n",
        "        print(\"Select Content Video:\")\n",
        "\n",
        "        list_files(VIDEOS_PATH)\n",
        "        \n",
        "        content = find_file(input(),Path(VIDEOS_PATH))\n",
        "        content = check_error(content,VIDEOS_PATH)\n",
        "        content_path  = Path(VIDEOS_PATH + \"/\" + content)\n",
        "\n",
        "        create_directory(IMAGES_PATH)\n",
        "        upload_files(IMAGES_PATH,1,\"one image\")\n",
        "\n",
        "        print(\"Select Style Image:\")\n",
        "\n",
        "        list_files(IMAGES_PATH)\n",
        "\n",
        "        image = find_file(input(),Path(IMAGES_PATH))\n",
        "        image = check_error(image,IMAGES_PATH)\n",
        "        image_path = Path(IMAGES_PATH + \"/\" + image)\n",
        "        \n",
        "        output =  'Result Gatys ' + os.path.splitext(content)[0] + '_' + os.path.splitext(image)[0]\n",
        "        output_path = Path(PATH + \"/\" + output + \".mp4\")\n",
        "\n",
        "        video_style_transfer_gatys(str(content_path), str(image_path), str(output_path))\n",
        "\n",
        "        print(\"video saved in Files folder, refresh Files to see it\")\n",
        "        \n",
        "        if(os.path.splitext(content)[1]==\".mp4\"):\n",
        "            files.download(output_path)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please upload at least one video\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f43070f7-9568-4117-a665-77fceda06cb8\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-f43070f7-9568-4117-a665-77fceda06cb8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Please upload at least one video\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-485ec53f-04fd-4632-9210-38da86a2faf0\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-485ec53f-04fd-4632-9210-38da86a2faf0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Please upload at least one video\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-25b0e79c-6e44-4530-8336-64cc14fd7dc1\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-25b0e79c-6e44-4530-8336-64cc14fd7dc1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Movie.mov to Movie.mov\n",
            "Select Content Video:\n",
            "Movie\n",
            "Please upload at least one image\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-78f1f9e9-ea1c-4583-a82c-5694a7a4f246\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-78f1f9e9-ea1c-4583-a82c-5694a7a4f246\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Wave.jpg to Wave.jpg\n",
            "Select Style Image:\n",
            "Wave\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 7s 0us/step\n",
            "computing features, please wait\n",
            "computing iteration 1\n",
            "computing iteration 2\n",
            "computing iteration 3\n",
            "computing iteration 4\n",
            "computing iteration 5\n",
            "computing iteration 6\n",
            "computing iteration 7\n",
            "computing iteration 8\n",
            "computing iteration 9\n",
            "computing iteration 10\n",
            "computing iteration 11\n",
            "computing iteration 12\n",
            "computing iteration 13\n",
            "computing iteration 14\n",
            "computing iteration 15\n",
            "computing iteration 16\n",
            "computing iteration 17\n",
            "computing iteration 18\n",
            "computing iteration 19\n",
            "computing iteration 20\n",
            "computing iteration 21\n",
            "computing iteration 22\n",
            "computing iteration 23\n",
            "computing iteration 24\n",
            "computing iteration 25\n",
            "computing iteration 26\n",
            "computing iteration 27\n",
            "computing iteration 28\n",
            "computing iteration 29\n",
            "computing iteration 30\n",
            "computing iteration 31\n",
            "computing iteration 32\n",
            "computing iteration 33\n",
            "computing iteration 34\n",
            "computing iteration 35\n",
            "computing iteration 36\n",
            "computing iteration 37\n",
            "computing iteration 38\n",
            "computing iteration 39\n",
            "computing iteration 40\n",
            "computing iteration 41\n",
            "computing iteration 42\n",
            "computing iteration 43\n",
            "computing iteration 44\n",
            "computing iteration 45\n",
            "computing iteration 46\n",
            "computing iteration 47\n",
            "computing iteration 48\n",
            "computing iteration 49\n",
            "computing iteration 50\n",
            "computing iteration 51\n",
            "computing iteration 52\n",
            "computing iteration 53\n",
            "computing iteration 54\n",
            "computing iteration 55\n",
            "computing iteration 56\n",
            "computing iteration 57\n",
            "computing iteration 58\n",
            "computing iteration 59\n",
            "computing iteration 60\n",
            "computing iteration 61\n",
            "computing iteration 62\n",
            "computing iteration 63\n",
            "computing iteration 64\n",
            "computing iteration 65\n",
            "computing iteration 66\n",
            "computing iteration 67\n",
            "computing iteration 68\n",
            "computing iteration 69\n",
            "computing iteration 70\n",
            "computing iteration 71\n",
            "computing iteration 72\n",
            "computing iteration 73\n",
            "computing iteration 74\n",
            "computing iteration 75\n",
            "computing iteration 76\n",
            "computing iteration 77\n",
            "computing iteration 78\n",
            "computing iteration 79\n",
            "computing iteration 80\n",
            "computing iteration 81\n",
            "computing iteration 82\n",
            "computing iteration 83\n",
            "computing iteration 84\n",
            "computing iteration 85\n",
            "computing iteration 86\n",
            "computing iteration 87\n",
            "computing iteration 88\n",
            "computing iteration 89\n",
            "computing iteration 90\n",
            "computing iteration 91\n",
            "computing iteration 92\n",
            "computing iteration 93\n",
            "computing iteration 94\n",
            "computing iteration 95\n",
            "computing iteration 96\n",
            "computing iteration 97\n",
            "computing iteration 98\n",
            "computing iteration 99\n",
            "computing iteration 100\n",
            "computing features, please wait\n",
            "computing iteration 1\n",
            "computing iteration 2\n",
            "computing iteration 3\n",
            "computing iteration 4\n",
            "computing iteration 5\n",
            "computing iteration 6\n",
            "computing iteration 7\n",
            "computing iteration 8\n",
            "computing iteration 9\n",
            "computing iteration 10\n",
            "computing iteration 11\n",
            "computing iteration 12\n",
            "computing iteration 13\n",
            "computing iteration 14\n",
            "computing iteration 15\n",
            "computing iteration 16\n",
            "computing iteration 17\n",
            "computing iteration 18\n",
            "computing iteration 19\n",
            "computing iteration 20\n",
            "computing iteration 21\n",
            "computing iteration 22\n",
            "computing iteration 23\n",
            "computing iteration 24\n",
            "computing iteration 25\n",
            "computing iteration 26\n",
            "computing iteration 27\n",
            "computing iteration 28\n",
            "computing iteration 29\n",
            "computing iteration 30\n",
            "computing iteration 31\n",
            "computing iteration 32\n",
            "computing iteration 33\n",
            "computing iteration 34\n",
            "computing iteration 35\n",
            "computing iteration 36\n",
            "computing iteration 37\n",
            "computing iteration 38\n",
            "computing iteration 39\n",
            "computing iteration 40\n",
            "computing iteration 41\n",
            "computing iteration 42\n",
            "computing iteration 43\n",
            "computing iteration 44\n",
            "computing iteration 45\n",
            "computing iteration 46\n",
            "computing iteration 47\n",
            "computing iteration 48\n",
            "computing iteration 49\n",
            "computing iteration 50\n",
            "computing iteration 51\n",
            "computing iteration 52\n",
            "computing iteration 53\n",
            "computing iteration 54\n",
            "computing iteration 55\n",
            "computing iteration 56\n",
            "computing iteration 57\n",
            "computing iteration 58\n",
            "computing iteration 59\n",
            "computing iteration 60\n",
            "computing iteration 61\n",
            "computing iteration 62\n",
            "computing iteration 63\n",
            "computing iteration 64\n",
            "computing iteration 65\n",
            "computing iteration 66\n",
            "computing iteration 67\n",
            "computing iteration 68\n",
            "computing iteration 69\n",
            "computing iteration 70\n",
            "computing iteration 71\n",
            "computing iteration 72\n",
            "computing iteration 73\n",
            "computing iteration 74\n",
            "computing iteration 75\n",
            "computing iteration 76\n",
            "computing iteration 77\n",
            "computing iteration 78\n",
            "computing iteration 79\n",
            "computing iteration 80\n",
            "computing iteration 81\n",
            "computing iteration 82\n",
            "computing iteration 83\n",
            "computing iteration 84\n",
            "computing iteration 85\n",
            "computing iteration 86\n",
            "computing iteration 87\n",
            "computing iteration 88\n",
            "computing iteration 89\n",
            "computing iteration 90\n",
            "computing iteration 91\n",
            "computing iteration 92\n",
            "computing iteration 93\n",
            "computing iteration 94\n",
            "computing iteration 95\n",
            "computing iteration 96\n",
            "computing iteration 97\n",
            "computing iteration 98\n",
            "computing iteration 99\n",
            "computing iteration 100\n",
            "computing features, please wait\n",
            "computing iteration 1\n",
            "computing iteration 2\n",
            "computing iteration 3\n",
            "computing iteration 4\n",
            "computing iteration 5\n",
            "computing iteration 6\n",
            "computing iteration 7\n",
            "computing iteration 8\n",
            "computing iteration 9\n",
            "computing iteration 10\n",
            "computing iteration 11\n",
            "computing iteration 12\n",
            "computing iteration 13\n",
            "computing iteration 14\n",
            "computing iteration 15\n",
            "computing iteration 16\n",
            "computing iteration 17\n",
            "computing iteration 18\n",
            "computing iteration 19\n",
            "computing iteration 20\n",
            "computing iteration 21\n",
            "computing iteration 22\n",
            "computing iteration 23\n",
            "computing iteration 24\n",
            "computing iteration 25\n",
            "computing iteration 26\n",
            "computing iteration 27\n",
            "computing iteration 28\n",
            "computing iteration 29\n",
            "computing iteration 30\n",
            "computing iteration 31\n",
            "computing iteration 32\n",
            "computing iteration 33\n",
            "computing iteration 34\n",
            "computing iteration 35\n",
            "computing iteration 36\n",
            "computing iteration 37\n",
            "computing iteration 38\n",
            "computing iteration 39\n",
            "computing iteration 40\n",
            "computing iteration 41\n",
            "computing iteration 42\n",
            "computing iteration 43\n",
            "computing iteration 44\n",
            "computing iteration 45\n",
            "computing iteration 46\n",
            "computing iteration 47\n",
            "computing iteration 48\n",
            "computing iteration 49\n",
            "computing iteration 50\n",
            "computing iteration 51\n",
            "computing iteration 52\n",
            "computing iteration 53\n",
            "computing iteration 54\n",
            "computing iteration 55\n",
            "computing iteration 56\n",
            "computing iteration 57\n",
            "computing iteration 58\n",
            "computing iteration 59\n",
            "computing iteration 60\n",
            "computing iteration 61\n",
            "computing iteration 62\n",
            "computing iteration 63\n",
            "computing iteration 64\n",
            "computing iteration 65\n",
            "computing iteration 66\n",
            "computing iteration 67\n",
            "computing iteration 68\n",
            "computing iteration 69\n",
            "computing iteration 70\n",
            "computing iteration 71\n",
            "computing iteration 72\n",
            "computing iteration 73\n",
            "computing iteration 74\n",
            "computing iteration 75\n",
            "computing iteration 76\n",
            "computing iteration 77\n",
            "computing iteration 78\n",
            "computing iteration 79\n",
            "computing iteration 80\n",
            "computing iteration 81\n",
            "computing iteration 82\n",
            "computing iteration 83\n",
            "computing iteration 84\n",
            "computing iteration 85\n",
            "computing iteration 86\n",
            "computing iteration 87\n",
            "computing iteration 88\n",
            "computing iteration 89\n",
            "computing iteration 90\n",
            "computing iteration 91\n",
            "computing iteration 92\n",
            "computing iteration 93\n",
            "computing iteration 94\n",
            "computing iteration 95\n",
            "computing iteration 96\n",
            "computing iteration 97\n",
            "computing iteration 98\n",
            "computing iteration 99\n",
            "computing iteration 100\n",
            "computing features, please wait\n",
            "computing iteration 1\n",
            "computing iteration 2\n",
            "computing iteration 3\n",
            "computing iteration 4\n",
            "computing iteration 5\n",
            "computing iteration 6\n",
            "computing iteration 7\n",
            "computing iteration 8\n",
            "computing iteration 9\n",
            "computing iteration 10\n",
            "computing iteration 11\n",
            "computing iteration 12\n",
            "computing iteration 13\n",
            "computing iteration 14\n",
            "computing iteration 15\n",
            "computing iteration 16\n",
            "computing iteration 17\n",
            "computing iteration 18\n",
            "computing iteration 19\n",
            "computing iteration 20\n",
            "computing iteration 21\n",
            "computing iteration 22\n",
            "computing iteration 23\n",
            "computing iteration 24\n",
            "computing iteration 25\n",
            "computing iteration 26\n",
            "computing iteration 27\n",
            "computing iteration 28\n",
            "computing iteration 29\n",
            "computing iteration 30\n",
            "computing iteration 31\n",
            "computing iteration 32\n",
            "computing iteration 33\n",
            "computing iteration 34\n",
            "computing iteration 35\n",
            "computing iteration 36\n",
            "computing iteration 37\n",
            "computing iteration 38\n",
            "computing iteration 39\n",
            "computing iteration 40\n",
            "computing iteration 41\n",
            "computing iteration 42\n",
            "computing iteration 43\n",
            "computing iteration 44\n",
            "computing iteration 45\n",
            "computing iteration 46\n",
            "computing iteration 47\n",
            "computing iteration 48\n",
            "computing iteration 49\n",
            "computing iteration 50\n",
            "computing iteration 51\n",
            "computing iteration 52\n",
            "computing iteration 53\n",
            "computing iteration 54\n",
            "computing iteration 55\n",
            "computing iteration 56\n",
            "computing iteration 57\n",
            "computing iteration 58\n",
            "computing iteration 59\n",
            "computing iteration 60\n",
            "computing iteration 61\n",
            "computing iteration 62\n",
            "computing iteration 63\n",
            "computing iteration 64\n",
            "computing iteration 65\n",
            "computing iteration 66\n",
            "computing iteration 67\n",
            "computing iteration 68\n",
            "computing iteration 69\n",
            "computing iteration 70\n",
            "computing iteration 71\n",
            "computing iteration 72\n",
            "computing iteration 73\n",
            "computing iteration 74\n",
            "computing iteration 75\n",
            "computing iteration 76\n",
            "computing iteration 77\n",
            "computing iteration 78\n",
            "computing iteration 79\n",
            "computing iteration 80\n",
            "computing iteration 81\n",
            "computing iteration 82\n",
            "computing iteration 83\n",
            "computing iteration 84\n",
            "computing iteration 85\n",
            "computing iteration 86\n",
            "computing iteration 87\n",
            "computing iteration 88\n",
            "computing iteration 89\n",
            "computing iteration 90\n",
            "computing iteration 91\n",
            "computing iteration 92\n",
            "computing iteration 93\n",
            "computing iteration 94\n",
            "computing iteration 95\n",
            "computing iteration 96\n",
            "computing iteration 97\n",
            "computing iteration 98\n",
            "computing iteration 99\n",
            "computing iteration 100\n",
            "computing features, please wait\n",
            "computing iteration 1\n",
            "computing iteration 2\n",
            "computing iteration 3\n",
            "computing iteration 4\n",
            "computing iteration 5\n",
            "computing iteration 6\n",
            "computing iteration 7\n",
            "computing iteration 8\n",
            "computing iteration 9\n",
            "computing iteration 10\n",
            "computing iteration 11\n",
            "computing iteration 12\n",
            "computing iteration 13\n",
            "computing iteration 14\n",
            "computing iteration 15\n",
            "computing iteration 16\n",
            "computing iteration 17\n",
            "computing iteration 18\n",
            "computing iteration 19\n",
            "computing iteration 20\n",
            "computing iteration 21\n",
            "computing iteration 22\n",
            "computing iteration 23\n",
            "computing iteration 24\n",
            "computing iteration 25\n",
            "computing iteration 26\n",
            "computing iteration 27\n",
            "computing iteration 28\n",
            "computing iteration 29\n",
            "computing iteration 30\n",
            "computing iteration 31\n",
            "computing iteration 32\n",
            "computing iteration 33\n",
            "computing iteration 34\n",
            "computing iteration 35\n",
            "computing iteration 36\n",
            "computing iteration 37\n",
            "computing iteration 38\n",
            "computing iteration 39\n",
            "computing iteration 40\n",
            "computing iteration 41\n",
            "computing iteration 42\n",
            "computing iteration 43\n",
            "computing iteration 44\n",
            "computing iteration 45\n",
            "computing iteration 46\n",
            "computing iteration 47\n",
            "computing iteration 48\n",
            "computing iteration 49\n",
            "computing iteration 50\n",
            "computing iteration 51\n",
            "computing iteration 52\n",
            "computing iteration 53\n",
            "computing iteration 54\n",
            "computing iteration 55\n",
            "computing iteration 56\n",
            "computing iteration 57\n",
            "computing iteration 58\n",
            "computing iteration 59\n",
            "computing iteration 60\n",
            "computing iteration 61\n",
            "computing iteration 62\n",
            "computing iteration 63\n",
            "computing iteration 64\n",
            "computing iteration 65\n",
            "computing iteration 66\n",
            "computing iteration 67\n",
            "computing iteration 68\n",
            "computing iteration 69\n",
            "computing iteration 70\n",
            "computing iteration 71\n",
            "computing iteration 72\n",
            "computing iteration 73\n",
            "computing iteration 74\n",
            "computing iteration 75\n",
            "computing iteration 76\n",
            "computing iteration 77\n",
            "computing iteration 78\n",
            "computing iteration 79\n",
            "computing iteration 80\n",
            "computing iteration 81\n",
            "computing iteration 82\n",
            "computing iteration 83\n",
            "computing iteration 84\n",
            "computing iteration 85\n",
            "computing iteration 86\n",
            "computing iteration 87\n",
            "computing iteration 88\n",
            "computing iteration 89\n",
            "computing iteration 90\n",
            "computing iteration 91\n",
            "computing iteration 92\n",
            "computing iteration 93\n",
            "computing iteration 94\n",
            "computing iteration 95\n",
            "computing iteration 96\n",
            "computing iteration 97\n",
            "computing iteration 98\n",
            "computing iteration 99\n",
            "computing iteration 100\n",
            "computing features, please wait\n",
            "computing iteration 1\n",
            "computing iteration 2\n",
            "computing iteration 3\n",
            "computing iteration 4\n",
            "computing iteration 5\n",
            "computing iteration 6\n",
            "computing iteration 7\n",
            "computing iteration 8\n",
            "computing iteration 9\n",
            "computing iteration 10\n",
            "computing iteration 11\n",
            "computing iteration 12\n",
            "computing iteration 13\n",
            "computing iteration 14\n",
            "computing iteration 15\n",
            "computing iteration 16\n",
            "computing iteration 17\n",
            "computing iteration 18\n",
            "computing iteration 19\n",
            "computing iteration 20\n",
            "computing iteration 21\n",
            "computing iteration 22\n",
            "computing iteration 23\n",
            "computing iteration 24\n",
            "computing iteration 25\n",
            "computing iteration 26\n",
            "computing iteration 27\n",
            "computing iteration 28\n",
            "computing iteration 29\n",
            "computing iteration 30\n",
            "computing iteration 31\n",
            "computing iteration 32\n",
            "computing iteration 33\n",
            "computing iteration 34\n",
            "computing iteration 35\n",
            "computing iteration 36\n",
            "computing iteration 37\n",
            "computing iteration 38\n",
            "computing iteration 39\n",
            "computing iteration 40\n",
            "computing iteration 41\n",
            "computing iteration 42\n",
            "computing iteration 43\n",
            "computing iteration 44\n",
            "computing iteration 45\n",
            "computing iteration 46\n",
            "computing iteration 47\n",
            "computing iteration 48\n",
            "computing iteration 49\n",
            "computing iteration 50\n",
            "computing iteration 51\n",
            "computing iteration 52\n",
            "computing iteration 53\n",
            "computing iteration 54\n",
            "computing iteration 55\n",
            "computing iteration 56\n",
            "computing iteration 57\n",
            "computing iteration 58\n",
            "computing iteration 59\n",
            "computing iteration 60\n",
            "computing iteration 61\n",
            "computing iteration 62\n",
            "computing iteration 63\n",
            "computing iteration 64\n",
            "computing iteration 65\n",
            "computing iteration 66\n",
            "computing iteration 67\n",
            "computing iteration 68\n",
            "computing iteration 69\n",
            "computing iteration 70\n",
            "computing iteration 71\n",
            "computing iteration 72\n",
            "computing iteration 73\n",
            "computing iteration 74\n",
            "computing iteration 75\n",
            "computing iteration 76\n",
            "computing iteration 77\n",
            "computing iteration 78\n",
            "computing iteration 79\n",
            "computing iteration 80\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-e6b3555c23e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mvideo_style_transfer_gatys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"video saved in Files folder, refresh Files to see it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-7ba9662ee986>\u001b[0m in \u001b[0;36mvideo_style_transfer_gatys\u001b[0;34m(video_path, style_path, output_path, batch_s)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mbatch_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_s\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_l\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_style_transfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mvideo_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-7ba9662ee986>\u001b[0m in \u001b[0;36mrun_style_transfer\u001b[0;34m(content, style, iterations, content_weight, style_weight, learning_rate)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"computing iteration \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-379454678a38>\u001b[0m in \u001b[0;36mcompute_gradient\u001b[0;34m(noise_img, noise_features_gen, img_features, loss_w, layers_n)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_features_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# Compute gradients wrt input image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-379454678a38>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(noise_features, img_features, loss_w, layers_n)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# Accumulate style losses from all layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mstyle_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccumulate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_style_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# Here, we equally weight each contribution of each loss layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-379454678a38>\u001b[0m in \u001b[0;36maccumulate_loss\u001b[0;34m(img_feature, layers_n, noise_feature, loss)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomb_content\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mweight_per_layer\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomb_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mr_binary_op_wrapper\u001b[0;34m(y, x)\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m   \u001b[0;31m# Propagate func.__doc__ to the wrappers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1129\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Case: Dense * Sparse.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   5053\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   5054\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Mul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5055\u001b[0;31m         _ctx._post_execution_callbacks, x, y)\n\u001b[0m\u001b[1;32m   5056\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5057\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}