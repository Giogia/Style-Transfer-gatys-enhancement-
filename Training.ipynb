{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Giogia/gatys_piu_bello/blob/master/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ytog81RotoZe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "from functools import reduce\n",
        "from operator import mul\n",
        "from google.colab import files\n",
        "from tensorflow.keras import Model\n",
        "from numpy import expand_dims, array\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.applications import vgg19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from IPython.display import HTML, display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3nn1VqFWWXQj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "STYLE_LAYERS = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "CONTENT_LAYERS = ['block4_conv2']\n",
        "\n",
        "def net_pro(img):\n",
        "    f = get_model()\n",
        "    return f(img)\n",
        "\n",
        "def get_model():\n",
        "    model = vgg19.VGG19()\n",
        "    model.trainable = False\n",
        "    style_feature = [model.get_layer(i).output for i in STYLE_LAYERS]\n",
        "    content_feature = [model.get_layer(i).output for i in CONTENT_LAYERS]\n",
        "    return Model(model.input, style_feature + content_feature)\n",
        "  \n",
        "def get_feat_style(net, layer):\n",
        "    return net[STYLE_LAYERS.index(layer) + len(CONTENT_LAYERS)]\n",
        "  \n",
        "def get_feat_content(net, layer):\n",
        "    return net[CONTENT_LAYERS.index(layer)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PiierSM4tS_Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "WEIGHTS_INIT_STDEV = .1\n",
        "\n",
        "\n",
        "def net(image):\n",
        "\n",
        "    conv1 = conv_layer(image, 32, 9, 1)\n",
        "    conv2 = conv_layer(conv1, 64, 3, 2)\n",
        "    conv3 = conv_layer(conv2, 128, 3, 2)\n",
        "    resid1 = residual_block(conv3, 3)\n",
        "    resid2 = residual_block(resid1, 3)\n",
        "    resid3 = residual_block(resid2, 3)\n",
        "    resid4 = residual_block(resid3, 3)\n",
        "    resid5 = residual_block(resid4, 3)\n",
        "    conv_t1 = conv_tranpose_layer(resid5, 64, 3, 2)\n",
        "    conv_t2 = conv_tranpose_layer(conv_t1, 32, 3, 2)\n",
        "    conv_t3 = conv_layer(conv_t2, 3, 9, 1, is_relu=False)\n",
        "    preds = tf.nn.tanh(conv_t3) * 150 + 255./2\n",
        "\n",
        "    return preds\n",
        "\n",
        "\n",
        "def conv_layer(image, filter_number, filter_size, strides, is_relu=True):\n",
        "\n",
        "    # make the convolution of the image and return the convolution\n",
        "\n",
        "    weights_initialization = conv_initialization_vars(image, filter_number, filter_size)\n",
        "    strides_shape = [1, strides, strides, 1]\n",
        "\n",
        "    # apply the filter to the image with a 2d convolution\n",
        "    image = tf.nn.conv2d(image, weights_initialization, strides_shape, padding='SAME')\n",
        "    image = _instance_norm(image)\n",
        "\n",
        "    if is_relu:\n",
        "        image = tf.nn.relu(image)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def conv_tranpose_layer(img, filter_number, filter_size, strides):\n",
        "\n",
        "    weights_initialized = conv_initialization_vars(img, filter_number, filter_size, transpose=True)\n",
        "\n",
        "    batch_size, rows, cols, in_channels = [i for i in img.get_shape()]\n",
        "    new_rows, new_cols = int(rows * strides), int(cols * strides)\n",
        "    new_shape = [batch_size, new_rows, new_cols, filter_number]\n",
        "\n",
        "    tf_shape = tf.stack(new_shape)\n",
        "    strides_shape = [1, strides, strides, 1]\n",
        "\n",
        "    convolution = tf.nn.conv2d_transpose(img, weights_initialized, tf_shape, strides_shape, padding='SAME')\n",
        "    convolution = _instance_norm(convolution)\n",
        "\n",
        "    return tf.nn.relu(convolution)\n",
        "\n",
        "\n",
        "def residual_block(img, filter_size=3):\n",
        "\n",
        "    tmp_convolution = conv_layer(img, 128, filter_size, 1)\n",
        "\n",
        "    # add the convolution to the original image\n",
        "    return img + conv_layer(tmp_convolution, 128, filter_size, 1, is_relu=False)\n",
        "\n",
        "\n",
        "def _instance_norm(img):\n",
        "\n",
        "    # set the shape of the input img\n",
        "    batch_size, rows, cols, in_channels = [i for i in img.get_shape()]\n",
        "    var_shape = [in_channels]\n",
        "\n",
        "    # calculate the mean and the variance of the img\n",
        "    mu, sigma_sq = tf.nn.moments(img, [1, 2], keep_dims=True)\n",
        "    shift = tf.Variable(tf.zeros(var_shape))\n",
        "    scale = tf.Variable(tf.ones(var_shape))\n",
        "    epsilon = 1e-3\n",
        "\n",
        "    # normalize the img input wrt the mean and the variance calculated\n",
        "    normalized = (img - mu) / (sigma_sq + epsilon) ** (.5)\n",
        "\n",
        "    return scale * normalized + shift\n",
        "\n",
        "\n",
        "def conv_initialization_vars(network, out_channels, filter_size, transpose=False):\n",
        "    \n",
        "    _, rows, cols, in_channels = [i.value for i in network.get_shape()]\n",
        "\n",
        "    if not transpose:\n",
        "        weights_shape = [filter_size, filter_size, in_channels, out_channels]\n",
        "    else:\n",
        "        weights_shape = [filter_size, filter_size, out_channels, in_channels]\n",
        "\n",
        "    # with tf truncated we output rnd values rom a truncated normal distribution\n",
        "    weights_init = tf.Variable(tf.truncated_normal(weights_shape, stddev=WEIGHTS_INIT_STDEV, seed=1), dtype=tf.float32)\n",
        "\n",
        "    return weights_init"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fx3cccfcw8Qp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_image(path):\n",
        "\n",
        "    max_dim = 1024\n",
        "\n",
        "    img = Image.open(path)\n",
        "\n",
        "    # resize image to max_dim\n",
        "    scale = max_dim / max(img.size)\n",
        "\n",
        "    if scale < 1:\n",
        "        scaled_width = round(img.size[0] * scale)\n",
        "        scaled_height = round(img.size[1] * scale)\n",
        "        img = img.resize((scaled_width, scaled_height))\n",
        "\n",
        "    #convert greyscale to rgb\n",
        "    img = img.convert(\"RGB\")\n",
        "\n",
        "    img = img_to_array(img)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def preprocess_image(img):\n",
        "\n",
        "    img = expand_dims(img, axis=0)\n",
        "\n",
        "    #normalize by mean = [103.939, 116.779, 123.68] and with channels BGR\n",
        "    img = preprocess_input(img)\n",
        "\n",
        "    return img\n",
        "  \n",
        "\n",
        "def get_img(src, img_size=False):\n",
        "    img = scipy.misc.imread(src, mode='RGB') # misc.imresize(, (256, 256, 3))\n",
        "    if not (len(img.shape) == 3 and img.shape[2] == 3):\n",
        "        img = np.dstack((img,img,img))\n",
        "    if img_size != False:\n",
        "        img = scipy.misc.imresize(img, img_size)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ufJLqoGMsePU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "M_PIXEL = np.array([123.68,  116.779,  103.939])\n",
        "\n",
        "\n",
        "def get_style_loss(layers, batch_size, style_features, style_weight, net):\n",
        "    style_losses = []\n",
        "    for style_layer in layers:\n",
        "        layer = get_feat_style(net, style_layer)\n",
        "        bs, height, width, filters = map(lambda i: i.value, layer.get_shape())\n",
        "        size = height * width * filters\n",
        "        feats = tf.reshape(layer, (bs, height * width, filters))\n",
        "        feats_t = tf.transpose(feats, perm=[0, 2, 1])\n",
        "        grams = tf.matmul(feats_t, feats) / size\n",
        "        style_gram = style_features[style_layer]\n",
        "        style_losses.append(2 * tf.nn.l2_loss(grams - style_gram) / style_gram.shape)\n",
        "    style_loss = style_weight * reduce(tf.add, style_losses) / batch_size\n",
        "    return style_loss\n",
        "\n",
        "\n",
        "def get_content_loss(layer, batch_size, content_features, content_weight, net):\n",
        "    lay = get_feat_content(net, layer)\n",
        "    content_size = t_size(content_features[layer]) * batch_size\n",
        "    assert t_size(content_features[layer]) == t_size(lay)\n",
        "    d_content = lay - content_features[layer]\n",
        "    content_loss = content_weight * 2 * tf.nn.l2_loss(d_content) / content_size\n",
        "    return content_loss\n",
        "\n",
        "\n",
        "def t_size(tensor):\n",
        "    return reduce(mul, (d.value for d in tensor.get_shape()[1:]), 1)\n",
        "\n",
        "\n",
        "def compute_loss(content_ph, style_target, weights, tv_weight, layers, batch_size, batch_shape, gen_network_vgg):\n",
        "    style_features = precompute_style_features(layers[1], style_target, gen_network_vgg)\n",
        "    content_features = get_content_net_and_features(layers[0], content_ph, gen_network_vgg)\n",
        "    content_ph = content_ph / 255.0\n",
        "    net = generate_net(content_ph, gen_network_vgg)\n",
        "    content_loss = get_content_loss(layers[0][0], batch_size, content_features, weights[0], net)\n",
        "    style_loss = get_style_loss(layers[1], batch_size, style_features, weights[1], net)\n",
        "\n",
        "    # total variation denoising\n",
        "    tv_y_size = t_size(content_ph[:, 1:, :, :])\n",
        "    tv_x_size = t_size(content_ph[:, :, 1:, :])\n",
        "    y_tv = tf.nn.l2_loss(content_ph[:, 1:, :, :] - content_ph[:, :batch_shape[1]-1, :, :])\n",
        "    x_tv = tf.nn.l2_loss(content_ph[:, :, 1:, :] - content_ph[:, :, :batch_shape[2]-1, :])\n",
        "    tv_loss = tv_weight*2*(x_tv/tv_x_size + y_tv/tv_y_size)/batch_size\n",
        "\n",
        "    return content_loss + style_loss + tv_loss\n",
        "\n",
        "\n",
        "def get_content_net_and_features(layers, content_ph, vgg):\n",
        "    # pre-compute content features\n",
        "    content_features = {}\n",
        "    content_net = vgg(content_ph - M_PIXEL)\n",
        "    for layer in layers:\n",
        "        content_features[layer] = get_feat_content(content_net, layer)\n",
        "    return content_features\n",
        "\n",
        "def precompute_style_features(layers, style_target, vgg):\n",
        "    style_features = {}\n",
        "    style_image = tf.placeholder(tf.float32, style_target.shape, name='style_image')\n",
        "    net = vgg(style_image - M_PIXEL)\n",
        "    style_pre = np.array(style_target)\n",
        "    for layer in layers:\n",
        "        features = get_feat_style(net, layer).eval(feed_dict={style_image: style_pre})\n",
        "        features = np.reshape(features, (-1, features.shape[3]))\n",
        "        gram = np.matmul(features.T, features) / features.size\n",
        "        style_features[layer] = gram\n",
        "    return style_features\n",
        "\n",
        "def generate_net(content_ph, vgg):\n",
        "    return vgg(net(content_ph) - M_PIXEL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o74nqUyssOsh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def optimize(content_folder, style, content_weight, style_weight, tv_weight, vgg, \n",
        "             epochs=2, batch_size=4, save_path='fns.ckpt', learning_rate=1e-3):\n",
        "    style_target = load_image(style)\n",
        "    style_target = preprocess_image(style_target)\n",
        "    content_targets = get_files(content_folder)\n",
        "    \n",
        "    batch_shape = (batch_size, 256, 256, 3)\n",
        "    layers = CONTENT_LAYERS, STYLE_LAYERS\n",
        "    weights = content_weight, style_weight\n",
        "\n",
        "    with tf.Graph().as_default(), tf.Session() as sess:\n",
        "        x_content = tf.placeholder(tf.float32, shape=batch_shape, name=\"x_content\")\n",
        "        # overall loss\n",
        "        loss = compute_loss(x_content, style_target, weights, tv_weight, layers, batch_size, batch_shape, vgg)\n",
        "        train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        print(\"started training\")\n",
        "        progressbar = display(progress(0,epochs), display_id=True)\n",
        "        for epoch in range(epochs):\n",
        "            sample = len(content_targets)\n",
        "            it = 0\n",
        "            while it * batch_size < sample:\n",
        "                curr = it * batch_size\n",
        "                step = curr + batch_size\n",
        "                x_batch = [get_img(img_p, (256, 256, 3)).astype(np.float32) for img_p in content_targets[curr:step]]\n",
        "                x_batch = np.array(x_batch, dtype=np.float32)\n",
        "                train_step.run(feed_dict={x_content: x_batch})\n",
        "                it += 1\n",
        "            progressbar.update(progress(it%epochs, epochs))\n",
        "        saver = tf.train.Saver()\n",
        "        saver.save(sess, save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rRK-kWPIk127",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def progress(value, max=100):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(value=value, max=max))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "roSx8i_fuGZR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH = os.getcwd()\n",
        "IMAGES_PATH = PATH + '/Images'\n",
        "CONTENT_IMAGE_PATH = IMAGES_PATH + '/Content'\n",
        "\n",
        "\n",
        "def find_file(filename, directory):\n",
        "    for file in os.listdir(directory):\n",
        "        if os.path.splitext(file)[0] == filename:\n",
        "            return file\n",
        "\n",
        "    return None\n",
        "\n",
        "    \n",
        "def create_directory(path):\n",
        "    \n",
        "    if not(os.path.isdir(path)):\n",
        "            os.mkdir(path)\n",
        "  \n",
        "  \n",
        "def upload_files(path,number, message):\n",
        "    \n",
        "    while(len(os.listdir(path))<number):\n",
        "            print(\"Please upload at least \"+message)\n",
        "            os.chdir(path)\n",
        "            files.upload()\n",
        "            os.chdir(PATH)\n",
        "            time.sleep(30)\n",
        "    \n",
        "      \n",
        "def list_files(path):\n",
        "  \n",
        "    for file in os.listdir(Path(path)):\n",
        "            print(os.path.splitext(file)[0])\n",
        "        \n",
        "def get_files(path):\n",
        "    return [os.path.join(path,os.path.splitext(file)[0] + \n",
        "                         os.path.splitext(file)[1]) for file in os.listdir(Path(path))]\n",
        "\n",
        "def check_error(var,path):\n",
        "  \n",
        "    while(var==None):\n",
        "            print(\"Please insert a correct Name (case sensitive input)\")\n",
        "            list_files(path)\n",
        "            var = find_file(input(),Path(path))\n",
        "            \n",
        "    return var\n",
        "  \n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    create_directory(IMAGES_PATH)\n",
        "    create_directory(CONTENT_IMAGE_PATH)\n",
        "    \n",
        "\n",
        "    print(\"Upload Content Images:\")\n",
        "    \n",
        "    upload_files(CONTENT_IMAGE_PATH,10000,\"10000 images\")\n",
        "    \n",
        "    print(\"Using the following images for content training:\")\n",
        "    list_files(CONTENT_IMAGE_PATH)\n",
        "    \n",
        "    content_path  = Path(CONTENT_IMAGE_PATH + '/')\n",
        "\n",
        "    print(\"Select Style Image:\")\n",
        "    \n",
        "    upload_files(IMAGES_PATH,2,\"style\")\n",
        "    \n",
        "    list_files(IMAGES_PATH)\n",
        "\n",
        "    style = find_file(input(),Path(IMAGES_PATH))\n",
        "    style = check_error(style,IMAGES_PATH)\n",
        "    style_path = Path(IMAGES_PATH + \"/\" + style)\n",
        "\n",
        "    output =  'Model_' + os.path.splitext(style)[0]\n",
        "    output_path = Path(PATH +\"/\"+ output + \".ckpt\")\n",
        "    open(output + \".ckpt\", \"wb\").close\n",
        "    content_weight = 7.5e0\n",
        "    style_weight = 1e2\n",
        "    tv_weight = 2e2\n",
        "    batch_size = 4\n",
        "    epochs = 1000\n",
        "    learning_rate=1e-3\n",
        "    optimize(content_path, style_path, content_weight, style_weight, tv_weight, \n",
        "             net_pro, epochs, batch_size, output_path, learning_rate)\n",
        "    \n",
        "    print(\"train model saved in Files folder, refresh Files to see it\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}